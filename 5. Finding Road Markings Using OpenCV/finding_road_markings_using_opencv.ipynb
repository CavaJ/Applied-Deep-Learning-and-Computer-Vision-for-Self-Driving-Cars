{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable Jedi for better autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# you can make it permanent by adding the following line to your Jupyter config file\n",
    "# ~/.jupyter/jupyter_notebook_config.py\n",
    "# c.Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing openCV\n",
    "import cv2\n",
    "\n",
    "#Displaying image\n",
    "\n",
    "image = cv2.imread('test_image.jpg')\n",
    "cv2.imshow('input_image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying grayscale image\n",
    "\n",
    "cv2.imshow('input_image', gray_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a Gaussian filter to smooth the image.\n",
    "# (5,5) is the kernel size (must be odd numbers like 3×3, 5×5, etc.).\n",
    "# The 0 at the end is the standard deviation (calculated automatically if set to 0).\n",
    "# Why Apply Blurring? \n",
    "# ✔ Reduces noise and unwanted small details.\n",
    "# ✔ Helps edge detection algorithms (like Canny) to focus on important edges.\n",
    "blur_conversion = cv2.GaussianBlur(gray_conversion, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('input_image', blur_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An edge is a region in an image where there is a sharp change in intensity or a sharp change in color between adjacent pixels in an image. This change over a series of pixels is known as the gradient.\n",
    "The canny function computes the gradient in all directions of a blurred image and will trace the strongest gradient as a series of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Canny Edge Detection Works:\n",
    "- Noise Reduction: Uses a Gaussian filter to smooth the image.\n",
    "- Gradient Calculation: Computes intensity gradients using Sobel operators.\n",
    "- Non-Maximum Suppression: Thin out edges to remove unwanted pixels.\n",
    "- Hysteresis Thresholding:\n",
    "    - Edges above threshold2 (155) are strong edges (kept).\n",
    "    - Edges below threshold1 (50) are discarded.\n",
    "    - Edges between 50-155 are kept only if connected to a strong edge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_conversion= cv2.cvtColor(lanelines_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_conversion = cv2.GaussianBlur(gray_conversion, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conversion = cv2.Canny(blur_conversion, 50, 155) # threshold1 - 50, threshold2 - 155; If you don’t set apertureSize, OpenCV defaults to 3, meaning it uses a 3×3 Sobel kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the strongest gradients are represented by the color white\n",
    "cv2.imshow('input_image', canny_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "          gray_conversion= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "          blur_conversion = cv2.GaussianBlur(gray_conversion, (5, 5), 0)\n",
    "          canny_conversion = cv2.Canny(blur_conversion, 50, 150)\n",
    "          return canny_conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "        # The height helps define the bottom part of the region.\n",
    "        Image_height = image.shape[0]\n",
    "        # Defines a triangular polygon with 3 points:\n",
    "        # (200, Image_height) → Bottom-left corner.\n",
    "        # (1100, Image_height) → Bottom-right corner.\n",
    "        # (550, 250) → Apex (top-middle)\n",
    "        # Why this shape?\n",
    "        # ✅ It focuses on the road ahead where lane lines appear.\n",
    "        # ✅ Excludes irrelevant areas like the sky, buildings, and nearby cars.\n",
    "        # polygons = np.array([[(200, Image_height), (1100, Image_height), (550, 250)]])\n",
    "        \n",
    "        # 4-dimensional polygon\n",
    "        polygons = np.array([[(0, int(Image_height)), (1100, Image_height), (550, 250), (0, int(Image_height*3/4))]])\n",
    "        # Creates an empty black image (same size as input).\n",
    "        # Used for masking.\n",
    "        image_mask = np.zeros_like(image)\n",
    "        # Fills the defined polygon with white (255, 255, 255) on the black mask.\n",
    "        # This allows processing only inside the region.\n",
    "        cv2.fillPoly(image_mask, polygons, (255, 255, 255))\n",
    "        return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704, 1279, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "print(image.shape)\n",
    "lanelines_image = np.copy(image)\n",
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', reg_of_interest(canny_conversion))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying bitwise_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "         image_height = image.shape[0]\n",
    "         # polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "         \n",
    "         # 4-dimensional polygon\n",
    "         polygons = np.array([[(0, int(image_height)), (1100, image_height), (550, 250), (0, int(image_height*3/4))]])\n",
    "         image_mask = np.zeros_like(image)\n",
    "         cv2.fillPoly(image_mask, polygons, (255, 255, 255)) # The mask now has a white polygon on a black background.\n",
    "         \n",
    "         # bitwise_and multiplies all the bits in the black region of the image by 0 (all these parts becomes black in the original image) and the white region by 1111 (keeping the pixels in the original image in that area).\n",
    "         masking_image = cv2.bitwise_and(image, image_mask) # keeps only the polygon area from the original (e.g. cannied) image\n",
    "         \n",
    "         return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conversion = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_egde(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "         image_height = image.shape[0]\n",
    "         # polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "            \n",
    "         # 4-dimensional polygon\n",
    "         polygons = np.array([[(0, int(image_height)), (1100, image_height), (550, 250), (0, int(image_height*3/4))]])\n",
    "         image_mask = np.zeros_like(image)\n",
    "         cv2.fillPoly(image_mask, polygons, (255, 255, 255))\n",
    "         masking_image = cv2.bitwise_and(image, image_mask)\n",
    "         return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "            lines_image = np.zeros_like(image)\n",
    "            if lines is not None:\n",
    "                for line in lines:\n",
    "                    # line is a NumPy array of shape (1, 4), so reshape(4) converts it into four separate values:\n",
    "                    # (X1, Y1) → Start point of the line.\n",
    "                    # (X2, Y2) → End point of the line.\n",
    "                    X1, Y1, X2, Y2 = line.reshape(4)\n",
    "                    # Draws a blue line ((255,0,0)) between (X1, Y1) and (X2, Y2). Line thickness = 10 pixels.\n",
    "                    # Color Format: OpenCV uses BGR, not RGB, so:\n",
    "                    # (255, 0, 0) = Blue\n",
    "                    # (0, 255, 0) = Green\n",
    "                    # (0, 0, 255) = Red\n",
    "                    cv2.line(lines_image, (X1, Y1), (X2, Y2), (255,0,0), 10)\n",
    "            return lines_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_conv = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.HoughLinesP(image, rho, theta, threshold, array, minLineLength, maxLineGap)`\n",
    "\n",
    "Parameter\tDescription:\n",
    "    \n",
    "- `image`\tInput binary image\n",
    "- `rho=2`\tDistance resolution of the accumulator in pixels.\n",
    "- `theta=np.pi/180`\tAngular resolution of the accumulator in radians (1-degree step).\n",
    "- `threshold=100`\tMinimum number of votes needed to be considered a line.\n",
    "- `np.array([])`\tPlaceholder for optional parameters (not used).\n",
    "- `minLineLength=40`\tMinimum length of a line (shorter segments are discarded).\n",
    "- `maxLineGap=5`\tMaximum gap allowed between points on the same line (to connect broken lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns detected lines and assign them to lane_lines\n",
    "lane_lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "linelines_image = show_lines(lanelines_image, lane_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', linelines_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining with actual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "lane_image = np.copy(image)\n",
    "canny = canny_edge(lane_image)\n",
    "cropped_image = reg_of_interest(canny)\n",
    "lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)\n",
    "lines_image = show_lines(lane_image, lines)\n",
    "combine_image = cv2.addWeighted(lane_image, 0.8, lines_image, 1, 1) # Combine this with lane detection by overlaying the lines onto the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', combine_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have learned how to identify lane lines in an image. We took these lines and placed them on a random black image that has the same dimensions as our original image. \n",
    "By blending the two, we were able to ultimately place our detected lines back onto our original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the detected road marking in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization the detected road markings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will collect the line_parameters value (the average of all the slopes) from the average_slope_intercept fucntion and unpack it. We will set y2 to 3/5 * y1 as we want to consider \n",
    "# the line up to 3/5 of the y-axis. We know that the equation of a straight line is y = m*x + c, so we can rewrite it. We are going to find x1, y1 and x2, y2 by using the following function.\n",
    "def make_coordinates(image, line_parameters):\n",
    "          slope, intercept = line_parameters\n",
    "          y1 = image.shape[0]\n",
    "          y2 = int(y1*(3/5))\n",
    "          x1 = int((y1- intercept)/slope)\n",
    "          x2 = int((y2 - intercept)/slope)\n",
    "          return np.array([x1, y1, x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function averages out the slopes and y-intercepts into a single-line\n",
    "def average_slope_intercept(image, lines):\n",
    "          image_width = image.shape[1]\n",
    "          image_height = image.shape[0]\n",
    "          \n",
    "          # left_fit and right_fit are the lists that collected the coordinates of the average value of the lines on the left and right sides.\n",
    "          left_fit = []\n",
    "          middle_fit = []\n",
    "          right_fit = []\n",
    "          # here, we looped all the lines and reshaped them into a four-dimensional array using line.reshape(4).  \n",
    "          for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            # fits a first-degree polynomial (a linear function)\n",
    "            # it fits the polynomial of x and y and returns a vector of coefficients that describes the slope and intercept of a line.\n",
    "            parameter = np.polyfit((x1, x2), (y1, y2), 1) # fits the line for (x1, y1) and (x2, y2)\n",
    "            slope = parameter[0]\n",
    "            intercept = parameter[1]\n",
    "            # we know that the value of the slope is always negative for the left side of the line, and we wrote a condition to append all the slope values on the left side and right side of the image. Since, origina is at the top-left, x is horizantal and y is vertical axe.\n",
    "            if x1 < image_width / 5 and slope < 0:\n",
    "              left_fit.append((slope, intercept))\n",
    "            elif image_width / 5 <= x1 and x1 <= 1 * image_width / 2 and slope < 0:\n",
    "              middle_fit.append((slope, intercept))\n",
    "            else:\n",
    "              right_fit.append((slope, intercept))\n",
    "          # then, we averaged out the intercepts (slope and y-intercept) of the left side and right side using np.average\n",
    "          left_fit_average =np.average(left_fit, axis=0)\n",
    "          middle_fit_average = np.average(middle_fit, axis=0)\n",
    "          right_fit_average = np.average(right_fit, axis =0)\n",
    "          # find the x and y coordinates of the line using the make_coordinates function\n",
    "          left_line = make_coordinates(image, left_fit_average)\n",
    "          middle_line = make_coordinates(image, middle_fit_average)\n",
    "          right_line = make_coordinates(image, right_fit_average)\n",
    "          \n",
    "          return np.array([left_line, middle_line, right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_coversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "          lanelines_image = np.zeros_like(image)\n",
    "          if lines is not None:\n",
    "            for line in lines:\n",
    "              X1, Y1, X2, Y2 = line.reshape(4)\n",
    "              cv2.line(lanelines_image, (X1, Y1), (X2, Y2), (255,0,0), 10)\n",
    "          return lanelines_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "          image_height = image.shape[0]\n",
    "          # polygons = np.array([[(200, image_height), (1100, image_height), (551, 250)]])\n",
    "          \n",
    "          # 4-dimensional polygon\n",
    "          polygons = np.array([[(0, int(image_height)), (1100, image_height), (550, 250), (0, int(image_height*3/4))]])\n",
    "          image_mask = np.zeros_like(image)\n",
    "          cv2.fillPoly(image_mask, polygons, (255, 255, 255))\n",
    "          masking_image = cv2.bitwise_and(image, image_mask)\n",
    "          return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanelines_image = np.copy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_image = canny_edge(lanelines_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = reg_of_interest(canny_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength= 40, maxLineGap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_lines = average_slope_intercept(lanelines_image, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_image = show_lines(lanelines_image, averaged_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_image = cv2.addWeighted(lanelines_image, 0.8, line_image, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('result', combine_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting road markings in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting road markings in video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image, line_parameters):\n",
    "          try:\n",
    "            slope, intercept = line_parameters\n",
    "          except TypeError:\n",
    "            slope, intercept = 0.001,0\n",
    "          #slope, intercept = line_parameters\n",
    "          y1 = image.shape[0]\n",
    "          y2 = int(y1*(3/5))\n",
    "          x1 = int((y1- intercept)/slope)\n",
    "          x2 = int((y2 - intercept)/slope)\n",
    "          return np.array([x1, y1, x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(image, lines):\n",
    "          image_width = image.shape[1]\n",
    "          image_height = image.shape[0]\n",
    "          \n",
    "          # left_fit and right_fit are the lists that collected the coordinates of the average value of the lines on the left and right sides.\n",
    "          left_fit = []\n",
    "          middle_fit = []\n",
    "          right_fit = []\n",
    "          # here, we looped all the lines and reshaped them into a four-dimensional array using line.reshape(4).  \n",
    "          for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            # fits a first-degree polynomial (a linear function)\n",
    "            # it fits the polynomial of x and y and returns a vector of coefficients that describes the slope and intercept of a line.\n",
    "            parameter = np.polyfit((x1, x2), (y1, y2), 1) # fits the line for (x1, y1) and (x2, y2)\n",
    "            slope = parameter[0]\n",
    "            intercept = parameter[1]\n",
    "            # we know that the value of the slope is always negative for the left side of the line, and we wrote a condition to append all the slope values on the left side and right side of the image. Since, origina is at the top-left, x is horizantal and y is vertical axe.\n",
    "            if slope < 0: # x1 < image_width / 6 and slope < 0:\n",
    "              left_fit.append((slope, intercept))\n",
    "            #elif image_width / 6 <= x1 and x1 <= 1 * image_width / 2 and slope < 0:\n",
    "            #  middle_fit.append((slope, intercept))\n",
    "            else:\n",
    "              right_fit.append((slope, intercept))\n",
    "          # then, we averaged out the intercepts (slope and y-intercept) of the left side and right side using np.average\n",
    "          left_fit_average =np.average(left_fit, axis=0)\n",
    "          # middle_fit_average = np.average(middle_fit, axis=0)\n",
    "          right_fit_average = np.average(right_fit, axis =0)\n",
    "          # find the x and y coordinates of the line using the make_coordinates function\n",
    "          left_line = make_coordinates(image, left_fit_average)\n",
    "          # middle_line = make_coordinates(image, middle_fit_average)\n",
    "          right_line = make_coordinates(image, right_fit_average)\n",
    "          \n",
    "          return np.array([left_line, # middle_line, \n",
    "                           right_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(image):\n",
    "         gray_conversion= cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "         blur_conversion = cv2.GaussianBlur(gray_conversion, (5,5),0)\n",
    "         canny_conversion = cv2.Canny(blur_conversion, 50,150)\n",
    "         return canny_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lines(image, lines):\n",
    "          line_image = np.zeros_like(image)\n",
    "          if lines is not None:\n",
    "            for line in lines:\n",
    "              x1, y1, x2, y2 = line.reshape(4)\n",
    "              cv2.line(line_image, (x1, y1), (x2, y2), (255,0,0), 10)\n",
    "          return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_of_interest(image):\n",
    "          image_height = image.shape[0]\n",
    "          polygons = np.array([[(200, image_height), (1100, image_height), (550, 250)]])\n",
    "          \n",
    "          # 4-dimensional polygon\n",
    "          # polygons = np.array([[(0, int(image_height)), (1100, image_height), (550, 250), (0, int(image_height*3/4))]])\n",
    "          image_mask = np.zeros_like(image)\n",
    "          cv2.fillPoly(image_mask, polygons, 255)\n",
    "          masking_image = cv2.bitwise_and(image,image_mask)\n",
    "          return masking_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(3))  # Width\n",
    "frame_height = int(cap.get(4)) # Height\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')  # Use 'XVID' for .avi\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CavaJ\\anaconda3\\envs\\tf_env\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\CavaJ\\anaconda3\\envs\\tf_env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video or cannot fetch frame.\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "            ret, frame = cap.read()  # ret: Boolean (True if frame is read correctly)\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"End of video or cannot fetch frame.\")\n",
    "                break  # Exit loop if frame is empty\n",
    "            \n",
    "            # Process the frame\n",
    "            canny_image = canny_edge(frame)\n",
    "            cropped_canny = reg_of_interest(canny_image)\n",
    "            lines = cv2.HoughLinesP(cropped_canny, 2, np.pi/180, 100, np.array([]), minLineLength=40,maxLineGap=5)\n",
    "            averaged_lines = average_slope_intercept(frame, lines)\n",
    "            line_image = show_lines(frame, averaged_lines)\n",
    "            combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)\n",
    "            \n",
    "            # Write processed frame to output video\n",
    "            out.write(combo_image)\n",
    "            \n",
    "            # Show the result\n",
    "            cv2.imshow(\"result\", combo_image)\n",
    "            \n",
    "            # Quit when 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "cap.release()\n",
    "out.release()  # Save the video file\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
